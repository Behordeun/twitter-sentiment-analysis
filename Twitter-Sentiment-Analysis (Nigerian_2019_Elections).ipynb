{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20a27730",
   "metadata": {},
   "source": [
    "## Importing necessary library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad976000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98c26a",
   "metadata": {},
   "source": [
    "## Creating a data frame called \"df\" for storing the data to be scraped.  Here, \"2019 Elections\" was the search keyword\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35523b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"2019 elections\"').get_items(), 5000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d75c0b",
   "metadata": {},
   "source": [
    "## Reading the column names from the dataframe to check the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f96e36f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd8f285",
   "metadata": {},
   "source": [
    "## Calculate the time for scraping the 5000000 tweets\n",
    "\n",
    "Here our search parameters are modified to search for tweets around Abuja within __2017-01-01 to 2021-10-23__ using the keyword __2019 elections__. \n",
    "\n",
    "__NB:__ we set the result to be returned to __5000000__ so we can get as much as possible results (tweets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91acb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set start time\n",
    "start_time = datetime.now()\n",
    "#Creating dataframe called 'data' and storing the tweets\n",
    "data = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
    "    '\"2019 elections near:Abuja since:2017-01-01 until:2021-10-23\"').get_items(), 5000000))\n",
    "# Set end time\n",
    "end_time = datetime.now()\n",
    "#Printing the time duration for scraping these tweets\n",
    "print('Duration: {}'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986510d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only date, id, content, user, and url and stored into dataframe called 'df'\n",
    "df = data[['date', 'id', 'content', 'username', 'url']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d632678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have transformers library installed before, kindly install it using the command:\n",
    "# !pip install transformers.\n",
    "\n",
    "# PS: Remember to remove the leading # in front of \"pip install transformers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afbc451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the pipeline from Transformers.\n",
    "from transformers import pipeline\n",
    "sentiment_classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216102d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taking only 1000000 (20%) records and creating new dataframe called df1\n",
    "df1 = df.head(1000000)\n",
    "# Passing the tweets into the sentiment pipeline and extracting the sentiment score and label\n",
    "df1 = (df1.assign(sentiment = lambda x: x['content'].apply(lambda s: sentiment_classifier(s)))\n",
    ".assign(\n",
    "label = lambda x: x['sentiment'].apply(lambda s: (s[0]['label'])),\n",
    "score = lambda x: x['sentiment'].apply(lambda s: (s[0]['score']))))\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the 1000th tweet, to check the sentiment label whether it is \"positive\" or “negative”\n",
    "df1['content'][1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75c3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the sentiments\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x = df1[\"score\"],\n",
    "y = df1[\"label\"],\n",
    "orientation = \"h\")) #set orientation to horizontal because we want to flip the x and y-axis\n",
    "fig.update_layout(plot_bgcolor = \"white\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the entire 5000000 (100%) records and creating new dataframe called df1\n",
    "df2 = df\n",
    "# Passing the tweets into the sentiment pipeline and extracting the sentiment score and label\n",
    "df2 = (df2.assign(sentiment = lambda x: x['content'].apply(lambda s: sentiment_classifier(s)))\n",
    ".assign(\n",
    "label = lambda x: x['sentiment'].apply(lambda s: (s[0]['label'])),\n",
    "score = lambda x: x['sentiment'].apply(lambda s: (s[0]['score']))))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing the sentiments\n",
    "fig1 = go.Figure()\n",
    "fig1.add_trace(go.Bar(x = df2[\"Sentiment score\"],\n",
    "y = df2[\"Sentiment label\"],\n",
    "orientation = \"h\")) #set orientation to horizontal because we want to flip the x and y-axis\n",
    "fig1.update_layout(plot_bgcolor = \"white\")\n",
    "fig1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492f0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Abj-Elect-Tweets-Sentiment.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f785dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('Abj-Elect-Tweets-Sentiment1.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964d1976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
